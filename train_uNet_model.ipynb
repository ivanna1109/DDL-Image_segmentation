{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "920e2adb-6099-48d2-b48e-95a4b161b0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.1/41.1 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.1 scipy-1.14.0 threadpoolctl-3.5.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4ee682a-2f18-45d9-ab79-29d56aeff8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import flwr as fl\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6af8219a-3425-4556-bdcf-555dfb65c244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNet model definicija\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "        self.encoder1 = DoubleConv(in_channels, 64)\n",
    "        self.encoder2 = DoubleConv(64, 128)\n",
    "        self.encoder3 = DoubleConv(128, 256)\n",
    "        self.encoder4 = DoubleConv(256, 512)\n",
    "        self.encoder5 = DoubleConv(512, 1024)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.decoder4 = DoubleConv(1024, 512)\n",
    "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.decoder3 = DoubleConv(512, 256)\n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.decoder2 = DoubleConv(256, 128)\n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.decoder1 = DoubleConv(128, 64)\n",
    "\n",
    "        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool(enc1))\n",
    "        enc3 = self.encoder3(self.pool(enc2))\n",
    "        enc4 = self.encoder4(self.pool(enc3))\n",
    "        enc5 = self.encoder5(self.pool(enc4))\n",
    "\n",
    "        dec4 = self.upconv4(enc5)\n",
    "        dec4 = torch.cat((enc4, dec4), dim=1)\n",
    "        dec4 = self.decoder4(dec4)\n",
    "\n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = torch.cat((enc3, dec3), dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat((enc2, dec2), dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((enc1, dec1), dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "\n",
    "        return self.final_conv(dec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d528fee5-ea3f-4051-b573-3da9b4952977",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageMaskDataset():\n",
    "    def __init__(self, images, masks, transform=None):\n",
    "        self.images = images\n",
    "        self.masks = masks\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        mask = self.masks[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = torch.tensor(mask, dtype=torch.float32)\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "239dc35f-d4bb-444e-b0af-178e0a90631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle_data(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2937ca4-14b6-4279-8582-9c6281ecdea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_data = load_pickle_data('data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d89981e4-5104-4127-9758-def72836fe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dict = mri_data['images']\n",
    "masks_dict = mri_data['masks']\n",
    "\n",
    "images = [images_dict[key] for key in images_dict]\n",
    "masks = [masks_dict[key] for key in masks_dict]\n",
    "\n",
    "images = np.array(images)\n",
    "masks = np.array(masks)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4dfcf613-a93d-432e-80fe-7a082463536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, test_images, train_masks, test_masks = train_test_split(images, masks, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = ImageMaskDataset(train_images, train_masks, transform=transform)\n",
    "test_dataset = ImageMaskDataset(test_images, test_masks, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2fcf97ac-d4eb-4053-b3c8-13e87dc44317",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetClient(fl.client.NumPyClient):\n",
    "    def __init__(self, model, train_loader, test_loader):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
    "\n",
    "    def get_parameters(self):\n",
    "        return [val.cpu().numpy() for val in self.model.state_dict().values()]\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
    "        state_dict = {k: torch.tensor(v) for k, v in params_dict}\n",
    "        self.model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        self.model.train()\n",
    "        for epoch in range(config[\"epochs\"]):\n",
    "            for images, masks in self.train_loader:\n",
    "                images, masks = images.cuda(), masks.cuda()\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, masks)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "        return self.get_parameters(), len(self.train_loader.dataset), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        self.model.eval()\n",
    "        loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, masks in self.test_loader:\n",
    "                images, masks = images.cuda(), masks.cuda()\n",
    "                outputs = self.model(images)\n",
    "                loss += self.criterion(outputs, masks).item()\n",
    "        return float(loss / len(self.test_loader)), len(self.test_loader.dataset), {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9772ac57-2be0-41d1-ae7e-df2a662ae1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(3, 1).cuda() #radi sa rgb slikama, a kao ulaz produkuje binarnu masku, pa samo 1 kanal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d4fe4e04-0279-463a-a6e8-c3d00e596a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "35e070dd-07ce-4056-8b9d-b3a7656f78a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = UNetClient(model, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "569b93f3-748b-4f17-b0b7-a6ba4150567d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 10\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c1fbc2-7188-4626-88d5-ea2bcab96d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flower dokumentacija"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c20e9901-a131-430d-8a0b-90d45061235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1.0,  # Sample 100% of available clients for training\n",
    "    fraction_evaluate=0.5,  # Sample 50% of available clients for evaluation\n",
    "    min_fit_clients=10,  # Never sample less than 10 clients for training\n",
    "    min_evaluate_clients=5,  # Never sample less than 5 clients for evaluation\n",
    "    min_available_clients=10,  # Wait until all 10 clients are available\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "067de88b-ba83-4270-8d5b-c4f71edc6dfd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to import module `ray`.\n\nTo install the necessary dependencies, install `flwr` with the `simulation` extra:\n\n    pip install -U flwr[\"simulation\"]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Start simulation\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_clients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_CLIENTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mServerConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_resources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_resources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/flwr/simulation/__init__.py:36\u001b[0m, in \u001b[0;36mstart_simulation\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart_simulation\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Log error stating that module `ray` could not be imported.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(RAY_IMPORT_ERROR)\n",
      "\u001b[0;31mImportError\u001b[0m: Unable to import module `ray`.\n\nTo install the necessary dependencies, install `flwr` with the `simulation` extra:\n\n    pip install -U flwr[\"simulation\"]\n"
     ]
    }
   ],
   "source": [
    "# Start simulation\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client.to_client(),\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=5),\n",
    "    strategy=strategy,\n",
    "    client_resources=client_resources,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "61c43996-e638-4238-918b-408d39be7d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            output = model(data)\n",
    "            val_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total += data.size(0)\n",
    "    \n",
    "    val_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / total\n",
    "    \n",
    "    return val_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "96073951-c23a-40a7-9f37-961de115bef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    epochs = 30\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            train_loss += loss.item()\n",
    "    \n",
    "        train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "        val_loss, val_accuracy = evaluate_model(model, test_loader, criterion)\n",
    "    \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), f'UNET_best_model.pth')\n",
    "    \n",
    "        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
